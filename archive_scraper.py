import os
import json
import time
import requests
import google.generativeai as genai
from playwright.sync_api import sync_playwright

TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
CHANNEL_ID = os.environ.get("CHANNEL_ID")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
YOUR_CHANNEL_USERNAME = "peidano"

START_YEAR = 2015
END_YEAR = 2025
TOP_N_MONTHLY = 25
STATE_FILE = "archive_state.json"

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash-lite') 

MONTHS = {
    1: "January", 2: "February", 3: "March", 4: "April", 5: "May", 6: "June",
    7: "July", 8: "August", 9: "September", 10: "October", 11: "November", 12: "December"
}

def load_state():
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, "r") as f:
            return json.load(f)
    return {"year": START_YEAR, "month": 1, "product_idx": 0, "status": "MONTHLY"}

def save_state(state):
    with open(STATE_FILE, "w") as f:
        json.dump(state, f)
    
    os.system('git config --global user.email "bot@github.com"')
    os.system('git config --global user.name "Archive Bot"')
    os.system(f'git add {STATE_FILE}')
    os.system(f'git commit -m "Update state"')
    os.system('git push')

def generate_content(product_name, original_desc, launch_date):
    prompt_pitch = f"""
    Ù…ØªÙ† Ø®Ø§Ù… (ØªÙˆØ¶ÛŒØ­Ø§Øª Ø³Ø§Ø²Ù†Ø¯Ù‡): "{original_desc}"
    
    ÙˆØ¸ÛŒÙÙ‡: ØªÙˆ Ø³Ø±Ø¯Ø¨ÛŒØ± Ø§Ø±Ø´Ø¯ Ú©Ø§Ù†Ø§Ù„ Peidano Ù‡Ø³ØªÛŒ. Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø®Ø§Ø·Ø¨Ø§Ù† Ù…Ø¹Ø±ÙÛŒ Ú©Ù†.
    
    Ù‚ÙˆØ§Ù†ÛŒÙ† Ù†Ú¯Ø§Ø±Ø´:
    1. **Ù„Ø­Ù† Ø±Ø§ÙˆÛŒ:** Ù…ØªÙ† Ø±Ø§ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø§Ø² Ø²Ø¨Ø§Ù† Ø®ÙˆØ¯Øª (Ø³ÙˆÙ… Ø´Ø®Øµ / Ø¯Ø§Ù†Ø§ÛŒ Ú©Ù„) Ø¨Ù†ÙˆÛŒØ³. Ø§ØµÙ„Ø§Ù‹ Ø§Ø² Ù„Ø­Ù† ÙØ§Ù†Ø¯Ø± (Ø§ÙˆÙ„ Ø´Ø®Øµ / ØªØ¨Ù„ÛŒØºØ§ØªÛŒ) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†. Ù‡Ù…Ù‡ Ù¾Ø³Øªâ€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ù„Ø­Ù† ÛŒÚ©Ø¯Ø³Øª Ùˆ Ú˜ÙˆØ±Ù†Ø§Ù„ÛŒØ³ØªÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯.
    2. **Ù¾ÙˆØ´Ø´ Ú©Ø§Ù…Ù„:** Ù…ØªÙ† Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†ØŒ Ø¯Ø±Ú© Ú©Ù† Ùˆ Ø³Ù¾Ø³ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡:
       - Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ú†ÛŒØ³ØªØŸ (Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†ØŒ Ù¾Ù„ØªÙØ±Ù…ØŒ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ØŸ)
       - Ú†Ù‡ Ú©Ø§Ø±Ú©Ø±Ø¯ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ú†Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŸ
       - Ú†Ù‡ Ù…Ø´Ú©Ù„ÛŒ Ø±Ø§ Ø­Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ
    3. **Ø·ÙˆÙ„ Ù…ØªÙ†:** Ø¨ÛŒÙ† 5 ØªØ§ 15 Ø®Ø· (Ø¨Ø³ØªÙ‡ Ø¨Ù‡ ØºÙ†Ø§ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ).
    4. **Ø²Ø¨Ø§Ù†:** ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù†ØŒ Ø¬Ø°Ø§Ø¨ Ùˆ ØªØ®ØµØµÛŒ.
    """
    try:
        pitch_res = model.generate_content(prompt_pitch).text.strip()
        time.sleep(5)
    except:
        pitch_res = "ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    prompt_history = f"""
    Ù…Ø­ØµÙˆÙ„: {product_name}
    ØªØ§Ø±ÛŒØ® Ø¹Ø±Ø¶Ù‡: {launch_date}
    ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ù„ÛŒ: {original_desc[:200]}...

    ÙˆØ¸ÛŒÙÙ‡: Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø± Ø§Ø³ØªØ§Ø±ØªØ§Ù¾ØŒ ÛŒÚ© Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆØªØ§Ù‡ (3 ØªØ§ 5 Ø®Ø·) Ø¯Ø±Ø¨Ø§Ø±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø§Ù†Ø¬Ø§Ù… Ø¨Ø¯Ù‡.
    1. Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø¨Ø²Ø§Ø± Ø¬Ø³ØªØ¬Ùˆ (Search) ÛŒØ§ Ø¯Ø§Ù†Ø´ Ø®ÙˆØ¯Øª Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†: Ø§Ù„Ø§Ù† Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ú©Ø¬Ø§Ø³ØªØŸ (ÙØ¹Ø§Ù„ØŒ Ø´Ú©Ø³Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡ØŒ ÛŒØ§ Ø®Ø±ÛŒØ¯Ø§Ø±ÛŒ Ø´Ø¯Ù‡ØŸ)
    2. Ù…Ø¯Ù„ Ø¯Ø±Ø¢Ù…Ø¯ÛŒâ€ŒØ§Ø´ Ú†ÛŒØ³ØªØŸ
    3. Ù†Ú©ØªÙ‡ Ù…Ù‡Ù…: Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± Ø¨Ø®Ø´ "Ù…Ø¹Ø±ÙÛŒ Ù…Ø­ØµÙˆÙ„" Ù‚Ø§Ø¨Ù„ Ø­Ø¯Ø³ Ø§Ø³Øª Ø±Ø§ ØªÚ©Ø±Ø§Ø± Ù†Ú©Ù†. ÙÙ‚Ø· Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ø¯ÛŒØ¯ (ØªØ§Ø±ÛŒØ®Ú†Ù‡ØŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒØŒ Ø¨ÛŒØ²Ù†Ø³ Ù…Ø¯Ù„) Ø¨Ø¯Ù‡.
    4. Ø´Ø±ÙˆØ¹ Ø¬Ù…Ù„Ù‡ Ø­ØªÙ…Ø§Ù‹ Ø¨Ø§: "Ø¬Ù…Ù†Ø§ÛŒ: ..."
    """
    try:
        history_res = model.generate_content(prompt_history).text.strip()
        time.sleep(5)
    except:
        history_res = "Ø¬Ù…Ù†Ø§ÛŒ: Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØ§Ø±ÛŒØ®ÛŒ Ø¯Ù‚ÛŒÙ‚ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        
    return pitch_res, history_res

def send_to_telegram(data):
    caption = f"""
ðŸ—“ï¸ {data['date_str']}

{data['hashtags']}

**{data['title']}**

{data['pitch_text']}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{data['history_text']}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
**Product Hunt:** [View Page]({data['ph_link']})
**Website:** [Visit Site]({data['website']})
**Channel:** @{YOUR_CHANNEL_USERNAME}
"""
    media = []
    images = data['images'][:10]
    
    if not images:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        requests.post(url, json={"chat_id": CHANNEL_ID, "text": caption, "parse_mode": "Markdown"})
        return

    for i, img in enumerate(images):
        media_item = {"type": "photo", "media": img}
        if i == 0:
            media_item["caption"] = caption
            media_item["parse_mode"] = "Markdown"
        media.append(media_item)

    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMediaGroup"
    requests.post(url, json={"chat_id": CHANNEL_ID, "media": media})

def run_scraper():
    state = load_state()
    start_month_for_run = state['month']
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        while state['month'] == start_month_for_run:
            year = state['year']
            month = state['month']
            
            if year >= END_YEAR:
                break

            url = f"https://www.producthunt.com/leaderboard/monthly/{year}/{month}/all"
            
            try:
                page.goto(url, timeout=60000)
                page.wait_for_selector('div[class*="styles_item__"]', timeout=10000)
                
                for _ in range(5):
                    page.mouse.wheel(0, 1000)
                    time.sleep(1)

                items = page.locator('div[class*="styles_item__"]').all()
                items = items[:TOP_N_MONTHLY]
                
                current_idx = state['product_idx']
                
                if current_idx >= len(items):
                    state['month'] += 1
                    state['product_idx'] = 0
                    if state['month'] > 12:
                        state['month'] = 1
                        state['year'] += 1
                    save_state(state)
                    break

                item = items[current_idx]
                
                try:
                    title_el = item.locator('a[class*="styles_title__"]').first
                    title = title_el.inner_text()
                    ph_link = "https://www.producthunt.com" + title_el.get_attribute("href")
                    
                    tag_els = item.locator('a[class*="styles_topic__"]').all()
                    tags = [t.inner_text() for t in tag_els]
                    hashtags = " ".join([f"#{t.replace(' ', '')}" for t in tags])
                    
                except:
                    state['product_idx'] += 1
                    continue

                p_page = browser.new_page()
                try:
                    p_page.goto(ph_link, timeout=60000)
                    time.sleep(3)
                    
                    try:
                        website = p_page.locator('a[data-test="visit-button"]').first.get_attribute("href")
                    except:
                        website = ph_link

                    try:
                        desc = p_page.locator('div[class*="styles_description__"]').first.inner_text()
                    except:
                        desc = title

                    images = []
                    try:
                        img_els = p_page.locator('img[class*="styles_mediaImage__"]').all()
                        for img in img_els:
                            src = img.get_attribute("src")
                            if src and "http" in src:
                                images.append(src)
                        images = list(set(images))
                    except: pass
                    
                    p_page.close()

                    date_str = f"{MONTHS[month]} {year}"
                    pitch_text, history_text = generate_content(title, desc, date_str)
                    
                    post_data = {
                        "title": title,
                        "date_str": date_str,
                        "hashtags": hashtags,
                        "pitch_text": pitch_text,
                        "history_text": history_text,
                        "ph_link": ph_link,
                        "website": website,
                        "images": images
                    }
                    
                    send_to_telegram(post_data)
                    
                    state['product_idx'] += 1
                    save_state(state)
                    
                    time.sleep(5)

                except:
                    p_page.close()
                    state['product_idx'] += 1
                    save_state(state)

            except:
                time.sleep(10)

if __name__ == "__main__":
    run_scraper()